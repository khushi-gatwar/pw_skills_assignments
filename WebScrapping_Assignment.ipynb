{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788550c7-0a0b-48a2-aef2-f689bd59a378",
   "metadata": {},
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33147cf9-428a-4431-b5be-bc98b71d5a72",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting data from websites. It involves fetching web pages, parsing the HTML, and extracting the desired information. Web scraping can be done manually, but automated tools and scripts are often used to efficiently gather large amounts of data from websites.\n",
    "\n",
    "## Uses of Web Scrapping\n",
    "\n",
    "- Data Collection: Web scraping is used to collect data from websites that don't provide an API or have limited data export options.\n",
    "- Competitive Analysis: Businesses use web scraping to monitor competitors' prices, products, and strategies.\n",
    "- Research and Analysis: Researchers and analysts use web scraping to gather data for academic or market research.\n",
    "- Monitoring and Alerts: Web scraping is employed to monitor changes on websites and receive alerts for specific events.\n",
    "- Content Aggregation: Some services use web scraping to aggregate content from various sources for display on a single platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015486f4-ea62-4ab5-bb9f-1ea9b920260e",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4214ae22-1ad0-47a7-bc8a-8cefd973f43f",
   "metadata": {},
   "source": [
    "## Different Methods for Web Scraping:\n",
    "\n",
    "- Manual Scraping: Manually copying and pasting information from a website.\n",
    "- Regular Expressions: Using regular expressions to extract data from HTML content.\n",
    "- HTML Parsing Libraries: Using HTML parsing libraries like Beautiful Soup and lxml in Python.\n",
    "- Headless Browsers: Using headless browsers like Puppeteer or Selenium to automate interactions with websites.\n",
    "- APIs: Some websites provide APIs for accessing data programmatically, but when APIs are not available, web scraping becomes necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424398e4-8c47-4777-a50e-395a12bdc55f",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1d54c-e500-4895-b1ec-f643aa7654f7",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It provides Pythonic idioms for iterating, searching, and modifying the parse tree, making it easy to extract and manipulate data from HTML or XML documents.\n",
    "\n",
    "## Uses:\n",
    "\n",
    "- HTML Parsing: Beautiful Soup simplifies the process of parsing HTML and XML documents.\n",
    "- Tree Navigation: It provides methods and properties for navigating and searching the parse tree.\n",
    "- Data Extraction: Beautiful Soup makes it easy to extract data by searching for tags, attributes, or text.\n",
    "- HTML Modification: It allows for modifying the HTML structure by adding, modifying, or removing elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c378f58-68aa-47f7-8a9e-523cc4dadc0e",
   "metadata": {},
   "source": [
    "# Q4. Why is Flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c29eb-dee2-45dc-ae24-391528c4124a",
   "metadata": {},
   "source": [
    "Flask is used to create a web interface for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67843b60-484a-432a-9035-11bdc8e19a9e",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf78939-7025-42cc-9a70-60c532e9d721",
   "metadata": {},
   "source": [
    "## AWS services used:\n",
    "\n",
    "- code pipeline: to connect github code and beamstack\n",
    "- Elastic Beanstalk:  used to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44579e-a780-4ae0-8f56-db4dc0f8e1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
